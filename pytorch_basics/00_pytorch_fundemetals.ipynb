{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00. Pytorch fundementals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu126\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to tensors\n",
    "\n",
    "### Creating tensors\n",
    "\n",
    "Pytorch tensors are created by `torch.tensor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n",
      "0\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# Scalar\n",
    "scalar = torch.tensor(7)\n",
    "print(scalar)\n",
    "\n",
    "# Number of dimensions of a tensor\n",
    "print(scalar.ndim)\n",
    "\n",
    "# Get tensor back as python int \n",
    "print(scalar.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  4, 432,   3])\n",
      "1\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([4,432,3])\n",
    "print(vector)\n",
    "# Dimensions\n",
    "print(vector.ndim)\n",
    "# Shape\n",
    "print(vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Matrix, often uppercase nomenclature\n",
    "MATRIX = torch.tensor([[7,8], [23,3]])\n",
    "print(MATRIX.ndim)\n",
    "print(MATRIX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "3\n",
      "tensor([[23,  3, 23],\n",
      "        [ 2,  3,  4]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor, ofter uppercase nomenclature\n",
    "TENSOR = torch.tensor([[[23,3,23], [2,3,4]],\n",
    "                        [[23,32,3], [32,3,23]]])\n",
    "print(TENSOR.shape)\n",
    "print(TENSOR.ndim)\n",
    "print(TENSOR[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random tensors\n",
    "\n",
    "Random tensors are important because the way many neural networks work is that they start with random numbers, and then adjust those random numbers to better represent the data\n",
    "\n",
    "`Start with random numbers -> look at data -> update random numbers -> look at data -> update numbers...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2052, 0.5802, 0.2260, 0.9425],\n",
      "         [0.0592, 0.2300, 0.0947, 0.8146],\n",
      "         [0.1838, 0.2454, 0.6977, 0.9551]],\n",
      "\n",
      "        [[0.9094, 0.0112, 0.2670, 0.0648],\n",
      "         [0.6393, 0.6988, 0.2443, 0.7508],\n",
      "         [0.8663, 0.1499, 0.5250, 0.3760]]])\n",
      "3\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "#Creating a random tensor of size (2,3,4)\n",
    "random_tensor = torch.rand(2,3,4)\n",
    "print(random_tensor)\n",
    "print(random_tensor.ndim)\n",
    "print(random_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224]) 3\n"
     ]
    }
   ],
   "source": [
    "# Create a random tensor with a similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(3,224,224)) #height, width, color channels (R, G, B)\n",
    "print(random_image_size_tensor.shape, random_image_size_tensor.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]], dtype=torch.float64)\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor of all zeros \n",
    "zeros = torch.zeros(size = (3,4))\n",
    "print(zeros)\n",
    "print(zeros * random_tensor)\n",
    "\n",
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size = (3,4), dtype=float)\n",
    "print(ones)\n",
    "print(ones.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a range of tensors and tensor-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  39,   83,  127,  171,  215,  259,  303,  347,  391,  435,  479,  523,\n",
      "         567,  611,  655,  699,  743,  787,  831,  875,  919,  963, 1007, 1051,\n",
      "        1095, 1139, 1183, 1227, 1271, 1315, 1359, 1403, 1447, 1491, 1535, 1579,\n",
      "        1623, 1667, 1711, 1755, 1799, 1843, 1887, 1931, 1975, 2019, 2063, 2107,\n",
      "        2151, 2195, 2239, 2283, 2327, 2371, 2415, 2459, 2503, 2547, 2591, 2635,\n",
      "        2679, 2723, 2767, 2811, 2855, 2899, 2943, 2987, 3031, 3075, 3119, 3163,\n",
      "        3207])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0])\n"
     ]
    }
   ],
   "source": [
    "# Use torch.arange\n",
    "one_to_eleven =  torch.arange(start=39, end = 3234, step =44)\n",
    "print(one_to_eleven)\n",
    "\n",
    "# Creating tensors-like (the same shape as the inputted tensor)\n",
    "ten_zeros = torch.zeros_like(input = one_to_eleven)\n",
    "print(ten_zeros)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor datatypes\n",
    "\n",
    "**Note:** it is one of the 3 big errors you'll run into with PyTorch & deep learning:\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not the right shape\n",
    "3. Tensors not on rigth device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "# Float_32 tensor\n",
    "# Look at datatypes torch.dtypes\n",
    "float_32_tensor = torch.tensor([3.0,6.0,9.0], # 3 most important params\n",
    "                               dtype=torch.float32, # data type of your sensor\n",
    "                             device=None,# which device your tensor is o\n",
    "                             requires_grad=False) # Wheather or not to track gradients\n",
    "print(float_32_tensor.dtype)\n",
    "\n",
    "# Converting \n",
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "print(float_16_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3,  2, 32], dtype=torch.int32)\n",
      "tensor([  9.,  12., 288.])\n",
      "tensor([  9., 138.,  27.])\n"
     ]
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3,2,32], dtype=torch.int32)\n",
    "print(int_32_tensor)\n",
    "print(float_32_tensor * int_32_tensor)\n",
    "\n",
    "long_tensor = torch.tensor([3,23,3], dtype=torch.long)\n",
    "print(float_32_tensor * long_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting information from tensors (tensor attributes)\n",
    "\n",
    "device - .device\n",
    "\n",
    "data type - .dtype\n",
    "\n",
    "shape - .shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2741, 0.2541],\n",
      "        [0.2082, 0.6451],\n",
      "        [0.4031, 0.8766]], device='cuda:0')\n",
      "Device: cuda:0\n",
      "Data type: torch.float32\n",
      "Shape: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "some_tensor = torch.rand(size=(3,2), device=\"cuda\")\n",
    "print(some_tensor)\n",
    "print(f\"Device: {some_tensor.device}\\nData type: {some_tensor.dtype}\\nShape: {some_tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating tensors (tensor operations)\n",
    "\n",
    "Tensor operations:\n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplication (element-wise)\n",
    "* Multiplication (Matrix)\n",
    "* Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12, 13])\n",
      "tensor([110, 120, 130])\n",
      "tensor([1, 2, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([110, 120, 130])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor, and add 10\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor += 10\n",
    "print(tensor)\n",
    "print(tensor * 10) \n",
    "\n",
    "# Subtract\n",
    "print(tensor -10)\n",
    "\n",
    "# Try out PyTorch in-built functions\n",
    "torch.mul(tensor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multiplication\n",
    "\n",
    "3 main ways of performing multiplication in deep learning:\n",
    "* Element-wise multiplication\n",
    "* Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12, 13]) * tensor([11, 12, 13]) = tensor([121, 144, 169])\n",
      "tensor(434)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(434)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element wise \n",
    "print(tensor, \"*\", tensor , \"=\", tensor*tensor)\n",
    "\n",
    "# Matrix multiplication\n",
    "print(tensor @ tensor)\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(434)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor,tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Matrix multiplication rules\n",
    "1. The **inner dimensions** must match\n",
    "2. The resulting matrix has the shape of the outer dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m((torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m@\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m))\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;66;03m# Works (inner dimensions are the same), dim is 3x3\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43m@torch\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Doesn't work\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x3)"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "print((torch.rand(3,2) @ torch.rand(2,3)).shape) # Works (inner dimensions are the same), dim is 3x3\n",
    "torch.rand(3,2) @torch.rand(3,3) # Doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "torch.Size([2, 3])\n",
      "tensor([[1, 3, 5],\n",
      "        [2, 4, 6]])\n",
      "tensor([[ 76, 103],\n",
      "        [100, 136]])\n"
     ]
    }
   ],
   "source": [
    "# Shapes for matrix multiplications\n",
    "# Transposition\n",
    "tensor_A = torch.tensor([[1,2],\n",
    "                         [3,4],\n",
    "                         [5,6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7,10],\n",
    "                         [8,11],\n",
    "                         [9,12]])\n",
    "# tensor.T for to get the transpose of the tensor\n",
    "print(tensor_A.shape)\n",
    "print(tensor_A.T.shape)\n",
    "print(tensor_A.T)\n",
    "print(tensor_A.T @ tensor_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregation functions: min, max, mean, sum, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.arange(0,100,10)\n",
    "\n",
    "# Find the min\n",
    "torch.min(tensor), tensor.min()\n",
    "\n",
    "# Find teh max\n",
    "torch.max(tensor), tensor.max()\n",
    "\n",
    "# Find the mean, we have to convert to float, since the torch.mean() requires the float data type\n",
    "torch.mean(tensor.type(dtype=torch.float32)), tensor.type(dtype=torch.float32).mean()\n",
    "\n",
    "# Find the sum\n",
    "torch.sum(tensor), tensor.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Postional min and max (find the index of the minimum value in the tensor)\n",
    "tensor = torch.tensor([[3,23,52,2,0,32342], [3,23,32,23,32,-23]])\n",
    "tensor.argmin()\n",
    "tensor.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* Reshaping - reshapes the input tensor to the defined shape\n",
    "* View - return a view of and input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensors on top of each other (vstack - vertical), (hstack - horizontal)\n",
    "* Squeeze - removes all `1` dimensions from a tensor\n",
    "* Unsqueeze - add a `1` dimension to a target tensor\n",
    "* Permute - REturn a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]) torch.Size([9])\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]]) torch.Size([1, 9])\n",
      "tensor([[500,   2,   3,   4,   5,   6,   7,   8,   9]]) tensor([500,   2,   3,   4,   5,   6,   7,   8,   9])\n",
      "tensor([[500, 500, 500, 500],\n",
      "        [  2,   2,   2,   2],\n",
      "        [  3,   3,   3,   3],\n",
      "        [  4,   4,   4,   4],\n",
      "        [  5,   5,   5,   5],\n",
      "        [  6,   6,   6,   6],\n",
      "        [  7,   7,   7,   7],\n",
      "        [  8,   8,   8,   8],\n",
      "        [  9,   9,   9,   9]])\n",
      "tensor([500,   2,   3,   4,   5,   6,   7,   8,   9])\n",
      "tensor([[500],\n",
      "        [  2],\n",
      "        [  3],\n",
      "        [  4],\n",
      "        [  5],\n",
      "        [  6],\n",
      "        [  7],\n",
      "        [  8],\n",
      "        [  9]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1,10)\n",
    "print(x, x.shape)\n",
    "\n",
    "# Reshaping, add an extra dimension\n",
    "x_reshaped = x.reshape(1,3,3) # The dimensions have to be appropriate for the amount of elements\n",
    "print(x_reshaped)\n",
    "\n",
    "# Change the view\n",
    "z = x.view(1,9) # Z has the same reference to x, if we change z we also change x\n",
    "print(z, z.shape)\n",
    "z[:,0] = 500\n",
    "print(z,x)\n",
    "\n",
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x,x,x,x], dim = 1) # In which dimension do we stack together\n",
    "print(x_stacked)\n",
    "\n",
    "# Squeeze and Unsqueeze\n",
    "x_squeezed = torch.squeeze(x)\n",
    "print(x_squeezed)\n",
    "x_unsqueezed = torch.unsqueeze(x, 1)\n",
    "print(x_unsqueezed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous tensor: tensor([[[500,   2,   3],\n",
      "         [  4,   5,   6],\n",
      "         [  7,   8,   9]]])\n",
      "previous shape: torch.Size([1, 3, 3])\n",
      "new tensor: tensor([500,   2,   3,   4,   5,   6,   7,   8,   9])\n",
      "new tensor's shape: torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "# torch.squeeze() - removes all single dimensions from a target tensor\n",
    "print(f\"previous tensor: {x_reshaped}\")\n",
    "print(f\"previous shape: {x_reshaped.shape}\")\n",
    "print(f\"new tensor: {x_squeezed.squeeze()}\")\n",
    "print(f\"new tensor's shape: {x_squeezed.squeeze().shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous target: tensor([[500,   2,   3],\n",
      "        [  4,   5,   6],\n",
      "        [  7,   8,   9]])\n",
      "previous shape: torch.Size([3, 3])\n",
      "new tensor: tensor([[[[500,   2,   3],\n",
      "          [  4,   5,   6],\n",
      "          [  7,   8,   9]]]])\n",
      "new tensor's shape: torch.Size([3, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "#torch.unsqueeze() - adds a single dimensions to a target tensor at a specific dim\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"previous target: {x_squeezed}\")\n",
    "print(f\"previous shape: {x_squeezed.shape}\")\n",
    "print(f\"new tensor: {x_reshaped.unsqueeze(dim=0)}\")\n",
    "print(f\"new tensor's shape: {x_squeezed.unsqueeze(dim=1).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape: torch.Size([224, 224, 3])\n",
      "permuted shape: torch.Size([3, 224, 224])\n",
      "tensor(3000.)\n"
     ]
    }
   ],
   "source": [
    "# torch.permute - rearranges the dimensions of a target tensor in a specified order (returns a view!!!!)\n",
    "x_original = torch.rand(size=(224,224,3)) # heigth, width, color_channels\n",
    "\n",
    "# Permute the original tensor to rearragne the axis (or dim) order \n",
    "x_permuted = x_original.permute(2,0,1) # shifts axes 0 -> 1, 1 -> 2, 2 -> 0\n",
    "print(f\"original shape: {x_original.shape}\")\n",
    "print(f\"permuted shape: {x_permuted.shape}\")\n",
    "\n",
    "#it changes both values since it is a view!!!\n",
    "x_permuted[0,0,0] = 3000\n",
    "print(x_original[0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing (selecting data from tensors)\n",
    "\n",
    "Indexing with PyTorch is similar to indexing with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]]) torch.Size([1, 3, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor([1, 2, 3])\n",
      "tensor(5)\n",
      "tensor(9)\n",
      "tensor([[4, 5]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1,10).reshape(1,3,3)\n",
    "print(x,x.shape)\n",
    "\n",
    "#Lets index on our tensor\n",
    "print(x[0])\n",
    "print(x[0,0])\n",
    "print(x[0,1,1])\n",
    "print(x[0,2,2])\n",
    "\n",
    "# Slicing\n",
    "print(x[:,1,:2])\n",
    "\n",
    "x[:,1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch tensors & NumPy\n",
    "\n",
    "NumPy is a popular scientific Python numerical computing library\n",
    "\n",
    "And because of this, PyTorch has functionality to interact with it\n",
    "\n",
    "* Data in NumPy, want in PyTorch tensors -> `torch.from_numpy(ndarray)`\n",
    "* PyTorch tensor -> NumPy -> torch.Tensor.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4. 5. 6. 7.] tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n",
      "float64 torch.float64\n",
      "torch.float32\n",
      "[2. 3. 4. 5. 6. 7. 8.] tensor([1., 2., 3., 4., 5., 6., 7.])\n"
     ]
    }
   ],
   "source": [
    "# NumPy array to tensor, careful since the default numpy type is float 64\n",
    "import numpy as np\n",
    "\n",
    "arr = np.arange(1.0,8.0)\n",
    "tensor = torch.from_numpy(arr)\n",
    "print(arr, tensor)\n",
    "print(arr.dtype, tensor.dtype)\n",
    "\n",
    "#change the datatype\n",
    "tensor = tensor.type(dtype=torch.float32)\n",
    "print(tensor.dtype)\n",
    "\n",
    "\n",
    "# Change the value of the array, what will this do to the tensor -> we get a new tensor\n",
    "arr = arr + 1\n",
    "print(arr, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1. 1.]\n",
      "torch.float32 float32\n",
      "[2. 2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "# Tensor to numpy array\n",
    "tensor = torch.ones(6)\n",
    "arr  = tensor.numpy(force=True)\n",
    "print(tensor, arr)\n",
    "print(tensor.dtype, arr.dtype) # The dtype stays as the one in pytorch\n",
    "\n",
    "# Change the tensor, what happens to array\n",
    "tensor += 1\n",
    "print(arr, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility (trying to take the random out of random)\n",
    "\n",
    "In short how a neural network learns:\n",
    "\n",
    "`start with random numbers -> tensor operations -> update numbers ....`\n",
    "\n",
    "To reduce the randomness in neural networks and PyTorch comes the concept of **random seed** \n",
    "\n",
    "\n",
    "Extra resources: pytorch randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6945, 0.8916, 0.9035, 0.0687, 0.9752],\n",
      "        [0.6062, 0.3187, 0.0471, 0.3234, 0.0310],\n",
      "        [0.9752, 0.0089, 0.7499, 0.5467, 0.7973]]) tensor([[0.3786, 0.3189, 0.8153, 0.1934, 0.3732],\n",
      "        [0.8284, 0.6467, 0.9792, 0.2876, 0.4436],\n",
      "        [0.3637, 0.4556, 0.5367, 0.0697, 0.8862]])\n",
      "tensor([[False, False, False, False, False],\n",
      "        [False, False, False, False, False],\n",
      "        [False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# 2 Random tensors\n",
    "rand_a = torch.rand(size=(3,5))\n",
    "rand_b = torch.rand(size=(3,5))\n",
    "\n",
    "print(rand_a, rand_b)\n",
    "print(rand_a == rand_b) # element wise comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True, True, True],\n",
      "        [True, True, True, True, True],\n",
      "        [True, True, True, True, True]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593, 0.3904],\n",
      "        [0.6009, 0.2566, 0.7936, 0.9408, 0.1332],\n",
      "        [0.9346, 0.5936, 0.8694, 0.5677, 0.7411]]) tensor([[0.8823, 0.9150, 0.3829, 0.9593, 0.3904],\n",
      "        [0.6009, 0.2566, 0.7936, 0.9408, 0.1332],\n",
      "        [0.9346, 0.5936, 0.8694, 0.5677, 0.7411]])\n"
     ]
    }
   ],
   "source": [
    "# Let's make some random but reproducible tensors, set the random seed\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "random_c = torch.rand(size=(3,5))\n",
    "\n",
    "# if you do it before every one, they are the same tensors\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_d = torch.rand(size=(3,5))\n",
    "print(random_c == random_d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running tensors and PyTorch objects on GPUs (and making faster computations)\n",
    "\n",
    "GPUs = faster computation on numbers, thanks to CUDA + NVIDIA hardware + PyTorch working begind the scenes to make everything good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 15 12:00:22 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 561.03                 Driver Version: 561.03         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   39C    P8              3W /   75W |    1993MiB /   8188MiB |     32%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      4132    C+G   C:\\Windows\\System32\\ShellHost.exe           N/A      |\n",
      "|    0   N/A  N/A      8128    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A      8696    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A      8836    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A      9312    C+G   ..._x64__cw5n1h2txyewy\\WidgetBoard.exe      N/A      |\n",
      "|    0   N/A  N/A      9504    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     10456    C+G   ...\\Local\\slack\\app-4.42.117\\slack.exe      N/A      |\n",
      "|    0   N/A  N/A     13876    C+G   ...\\Local\\slack\\app-4.42.117\\slack.exe      N/A      |\n",
      "|    0   N/A  N/A     14172    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     14932    C+G   ...m Files\\Mozilla Firefox\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A     15348    C+G   ...m Files\\Mozilla Firefox\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A     15544    C+G   ...al\\Discord\\app-1.0.9182\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A     15652    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     15856      C   ...\\miniconda3\\envs\\pytorch\\python.exe      N/A      |\n",
      "|    0   N/A  N/A     16052    C+G   ...s\\System32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A     17372    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     17964    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Check for GPU access with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU access with PyTorch \n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # often used nam\n",
    "\n",
    "# Count the devices\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Putting tensors (and models) on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n",
      "tensor([1, 2, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Create a sensor, default is on the cpu\n",
    "tensor = torch.tensor([1,2,3], device=\"cpu\") # tensor on cpu (default is cpu anyway)\n",
    "print(tensor, tensor.device)\n",
    "\n",
    "# Move tensor to GPU (if available) \n",
    "tensor_on_gpu = tensor.to(device)\n",
    "print(tensor_on_gpu) # also tells which gpu it is on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Moving tensors back to the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If tensor is on GPU, you can't transfrom it to NumPy\n",
    "#tensor_on_gpu.numpy() -> doesn't work\n",
    "\n",
    "# So we must first set it to the CPU\n",
    "tensor_on_cpu = tensor_on_gpu.to(\"cpu\")\n",
    "print(tensor_on_cpu, tensor_on_cpu.device)\n",
    "tensor_on_cpu.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises & Extra curriculum\n",
    "**learnpytorch.io**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3990, 0.5167, 0.0249, 0.9401, 0.9459, 0.7967, 0.4150],\n",
      "        [0.8203, 0.2290, 0.9096, 0.1183, 0.0752, 0.4092, 0.9601],\n",
      "        [0.2093, 0.1940, 0.8909, 0.4387, 0.3570, 0.5454, 0.8299],\n",
      "        [0.2099, 0.7684, 0.4290, 0.2117, 0.6606, 0.1654, 0.4250],\n",
      "        [0.9927, 0.6964, 0.2472, 0.7028, 0.7494, 0.9303, 0.0494],\n",
      "        [0.0750, 0.7223, 0.9478, 0.3647, 0.2215, 0.7784, 0.6391],\n",
      "        [0.2077, 0.7045, 0.9609, 0.0594, 0.3358, 0.0616, 0.7030]],\n",
      "       device='cuda:0')\n",
      "tensor([[4.0383],\n",
      "        [3.5217],\n",
      "        [3.4651],\n",
      "        [2.8699],\n",
      "        [4.3682],\n",
      "        [3.7487],\n",
      "        [3.0329]], device='cuda:0')\n",
      "tensor([2.8699], device='cuda:0')\n",
      "tensor([4.3682], device='cuda:0')\n",
      "tensor([0.4963, 0.7682, 0.0885, 0.1320, 0.3074, 0.6341, 0.4901, 0.8964, 0.4556,\n",
      "        0.6323])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "\n",
    "tensor = torch.rand(size=(7,7), device=device)\n",
    "print(tensor)\n",
    "\n",
    "tensor_2 = torch.ones(size=(1,7), device=device)\n",
    "t = tensor @ tensor_2.T\n",
    "print(t)\n",
    "\n",
    "print(min(t))\n",
    "print(max(t))\n",
    "\n",
    "t = torch.rand(size=(1,1,1,10))\n",
    "print(t.squeeze())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
